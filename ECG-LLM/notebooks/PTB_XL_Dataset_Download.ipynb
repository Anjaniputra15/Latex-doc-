{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptb-xl-header"
   },
   "source": [
    "# PTB-XL 12-Lead ECG Dataset Download\n",
    "\n",
    "This notebook downloads the PTB-XL dataset from PhysioNet for ECG analysis.\n",
    "\n",
    "## Dataset Information\n",
    "- **Records**: 21,837 ECG recordings (10 seconds each)\n",
    "- **Patients**: 18,885 unique patients\n",
    "- **Leads**: Standard 12-lead ECG (I, II, III, aVR, aVL, aVF, V1-V6)\n",
    "- **Sampling Rates**: 100 Hz and 500 Hz available\n",
    "- **Size**: ~8GB total (100Hz: ~2GB, 500Hz: ~4GB)\n",
    "- **Format**: WFDB format with CSV metadata\n",
    "\n",
    "## Requirements\n",
    "1. Google Colab environment\n",
    "2. Google Drive for persistent storage (recommended)\n",
    "3. PhysioNet account (free registration at https://physionet.org/)\n",
    "\n",
    "## License\n",
    "PTB-XL is available under the Open Data Commons Attribution License v1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## üöÄ Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistent storage\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Google Drive mounted successfully\")\n",
    "\n",
    "# Set up data directory\n",
    "DATA_DIR = \"/content/drive/MyDrive/ECG-LLM-Data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(f\"üìÅ Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-packages"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install --upgrade wfdb scipy matplotlib seaborn tqdm requests\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-section"
   },
   "source": [
    "## üì• Download PTB-XL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up paths\n",
    "PTB_XL_DIR = Path(DATA_DIR) / \"ptb_xl\"\n",
    "PTB_XL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìç PTB-XL will be stored at: {PTB_XL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-function"
   },
   "outputs": [],
   "source": [
    "def download_file(url, filepath, desc=\"Downloading\"):\n",
    "    \"\"\"Download file with progress bar\"\"\"\n",
    "    if filepath.exists():\n",
    "        print(f\"‚úÖ {filepath.name} already exists, skipping\")\n",
    "        return True\n",
    "    \n",
    "    try:\n",
    "        print(f\"‚¨áÔ∏è Downloading {filepath.name}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        with open(filepath, 'wb') as file, tqdm(\n",
    "            desc=desc,\n",
    "            total=total_size,\n",
    "            unit='B',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as pbar:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "                pbar.update(len(chunk))\n",
    "        \n",
    "        print(f\"‚úÖ Downloaded {filepath.name}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to download {filepath.name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def extract_zip(zip_path, extract_to):\n",
    "    \"\"\"Extract zip file and remove original\"\"\"\n",
    "    print(f\"üì¶ Extracting {zip_path.name}...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            # Extract with progress\n",
    "            members = zip_ref.infolist()\n",
    "            for member in tqdm(members, desc=\"Extracting\"):\n",
    "                zip_ref.extract(member, extract_to)\n",
    "        \n",
    "        print(f\"‚úÖ Extracted to {extract_to}\")\n",
    "        \n",
    "        # Remove zip to save space\n",
    "        zip_path.unlink()\n",
    "        print(f\"üóëÔ∏è Removed {zip_path.name} to save space\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to extract {zip_path.name}: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-metadata"
   },
   "outputs": [],
   "source": [
    "# Download metadata files (small, always needed)\n",
    "print(\"üìã Downloading metadata files...\")\n",
    "\n",
    "metadata_urls = {\n",
    "    \"ptbxl_database.csv\": \"https://physionet.org/files/ptb-xl/1.0.3/ptbxl_database.csv\",\n",
    "    \"scp_statements.csv\": \"https://physionet.org/files/ptb-xl/1.0.3/scp_statements.csv\"\n",
    "}\n",
    "\n",
    "for filename, url in metadata_urls.items():\n",
    "    download_file(url, PTB_XL_DIR / filename, f\"Downloading {filename}\")\n",
    "\n",
    "print(\"‚úÖ Metadata files downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-records-100hz"
   },
   "outputs": [],
   "source": [
    "# Download 100Hz ECG records (recommended for development - smaller size)\n",
    "print(\"üìä Downloading 100Hz ECG records (~2GB)...\")\n",
    "print(\"‚è±Ô∏è This may take 10-15 minutes depending on internet speed\")\n",
    "\n",
    "records_100_url = \"https://physionet.org/files/ptb-xl/1.0.3/records100.zip\"\n",
    "records_100_zip = PTB_XL_DIR / \"records100.zip\"\n",
    "\n",
    "if download_file(records_100_url, records_100_zip, \"100Hz Records\"):\n",
    "    extract_zip(records_100_zip, PTB_XL_DIR)\n",
    "    print(\"‚úÖ 100Hz records ready\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to download 100Hz records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "optional-download-500hz"
   },
   "outputs": [],
   "source": [
    "# Optional: Download 500Hz ECG records (full resolution - larger size)\n",
    "DOWNLOAD_500HZ = False  # Set to True if you need full resolution\n",
    "\n",
    "if DOWNLOAD_500HZ:\n",
    "    print(\"üìä Downloading 500Hz ECG records (~4GB)...\")\n",
    "    print(\"‚è±Ô∏è This may take 20-30 minutes depending on internet speed\")\n",
    "    print(\"‚ö†Ô∏è Warning: This will use significant storage space\")\n",
    "    \n",
    "    records_500_url = \"https://physionet.org/files/ptb-xl/1.0.3/records500.zip\"\n",
    "    records_500_zip = PTB_XL_DIR / \"records500.zip\"\n",
    "    \n",
    "    if download_file(records_500_url, records_500_zip, \"500Hz Records\"):\n",
    "        extract_zip(records_500_zip, PTB_XL_DIR)\n",
    "        print(\"‚úÖ 500Hz records ready\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to download 500Hz records\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Skipping 500Hz records (set DOWNLOAD_500HZ = True to download)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify-section"
   },
   "source": [
    "## üîç Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify-download"
   },
   "outputs": [],
   "source": [
    "# Verify dataset integrity\n",
    "print(\"üîç Verifying dataset integrity...\")\n",
    "\n",
    "# Check database file\n",
    "db_path = PTB_XL_DIR / \"ptbxl_database.csv\"\n",
    "if db_path.exists():\n",
    "    df = pd.read_csv(db_path)\n",
    "    print(f\"‚úÖ Database file: {len(df):,} records found\")\n",
    "    print(f\"   - Unique patients: {df['patient_id'].nunique():,}\")\n",
    "    print(f\"   - Date range: {df['recording_date'].min()} to {df['recording_date'].max()}\")\n",
    "else:\n",
    "    print(\"‚ùå Database file not found\")\n",
    "\n",
    "# Check SCP statements\n",
    "scp_path = PTB_XL_DIR / \"scp_statements.csv\"\n",
    "if scp_path.exists():\n",
    "    scp_df = pd.read_csv(scp_path)\n",
    "    print(f\"‚úÖ SCP statements: {len(scp_df):,} diagnostic codes\")\n",
    "else:\n",
    "    print(\"‚ùå SCP statements file not found\")\n",
    "\n",
    "# Check records directories\n",
    "records_100 = PTB_XL_DIR / \"records100\"\n",
    "if records_100.exists():\n",
    "    count_100 = len(list(records_100.rglob(\"*.dat\")))\n",
    "    print(f\"‚úÖ 100Hz ECG files: {count_100:,} .dat files\")\n",
    "    \n",
    "    # Check folder structure\n",
    "    folders_100 = [d.name for d in records_100.iterdir() if d.is_dir()]\n",
    "    print(f\"   - Folders: {sorted(folders_100)}\")\n",
    "else:\n",
    "    print(\"‚ùå 100Hz records directory not found\")\n",
    "\n",
    "records_500 = PTB_XL_DIR / \"records500\"\n",
    "if records_500.exists():\n",
    "    count_500 = len(list(records_500.rglob(\"*.dat\")))\n",
    "    print(f\"‚úÖ 500Hz ECG files: {count_500:,} .dat files\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è 500Hz records not downloaded (optional)\")\n",
    "\n",
    "print(\"\\nüéâ Dataset verification completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "explore-section"
   },
   "source": [
    "## üìä Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-and-explore"
   },
   "outputs": [],
   "source": [
    "# Load and explore the dataset\n",
    "import wfdb\n",
    "import numpy as np\n",
    "\n",
    "# Load database\n",
    "df = pd.read_csv(PTB_XL_DIR / \"ptbxl_database.csv\")\n",
    "scp_df = pd.read_csv(PTB_XL_DIR / \"scp_statements.csv\")\n",
    "\n",
    "print(\"üìà Dataset Overview:\")\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Unique patients: {df['patient_id'].nunique():,}\")\n",
    "print(f\"Age range: {df['age'].min():.0f} - {df['age'].max():.0f} years\")\n",
    "print(f\"Gender distribution:\")\n",
    "print(df['sex'].value_counts())\n",
    "print(f\"\\nSampling rates available: {df['fs_hz'].unique()}\")\n",
    "print(f\"Record lengths: {df['length_s'].unique()} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-distribution"
   },
   "outputs": [],
   "source": [
    "# Visualize dataset distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Age distribution\n",
    "axes[0,0].hist(df['age'].dropna(), bins=30, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_title('Age Distribution')\n",
    "axes[0,0].set_xlabel('Age (years)')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "\n",
    "# Gender distribution\n",
    "gender_counts = df['sex'].value_counts()\n",
    "axes[0,1].pie(gender_counts.values, labels=['Male', 'Female'], autopct='%1.1f%%', startangle=90)\n",
    "axes[0,1].set_title('Gender Distribution')\n",
    "\n",
    "# Recording dates over time\n",
    "df['recording_date'] = pd.to_datetime(df['recording_date'])\n",
    "df['year'] = df['recording_date'].dt.year\n",
    "year_counts = df['year'].value_counts().sort_index()\n",
    "axes[1,0].bar(year_counts.index, year_counts.values, alpha=0.7, color='lightgreen')\n",
    "axes[1,0].set_title('Recordings by Year')\n",
    "axes[1,0].set_xlabel('Year')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Heart rate distribution (if available)\n",
    "if 'heart_rate' in df.columns:\n",
    "    axes[1,1].hist(df['heart_rate'].dropna(), bins=30, alpha=0.7, color='salmon')\n",
    "    axes[1,1].set_title('Heart Rate Distribution')\n",
    "    axes[1,1].set_xlabel('Heart Rate (bpm)')\n",
    "    axes[1,1].set_ylabel('Count')\n",
    "else:\n",
    "    axes[1,1].text(0.5, 0.5, 'Heart Rate\\nData Not Available', \n",
    "                   ha='center', va='center', transform=axes[1,1].transAxes, fontsize=14)\n",
    "    axes[1,1].set_title('Heart Rate Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sample-section"
   },
   "source": [
    "## üî¨ Load Sample ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-sample-ecg"
   },
   "outputs": [],
   "source": [
    "# Load a sample ECG record\n",
    "print(\"üì° Loading sample ECG record...\")\n",
    "\n",
    "# Get first record path\n",
    "sample_record = df.iloc[0]\n",
    "record_path = str(PTB_XL_DIR / \"records100\" / sample_record['filename_lr'])\n",
    "\n",
    "print(f\"Loading: {sample_record['filename_lr']}\")\n",
    "print(f\"Patient: {sample_record['patient_id']}, Age: {sample_record['age']}, Sex: {sample_record['sex']}\")\n",
    "\n",
    "try:\n",
    "    # Load ECG signal\n",
    "    signal, fields = wfdb.rdsamp(record_path)\n",
    "    \n",
    "    print(f\"‚úÖ Signal loaded successfully\")\n",
    "    print(f\"   - Shape: {signal.shape} (samples √ó leads)\")\n",
    "    print(f\"   - Sampling rate: {fields['fs']} Hz\")\n",
    "    print(f\"   - Duration: {signal.shape[0] / fields['fs']:.1f} seconds\")\n",
    "    print(f\"   - Lead names: {fields['sig_name']}\")\n",
    "    \n",
    "    # Plot the 12-lead ECG\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    time_axis = np.arange(signal.shape[0]) / fields['fs']\n",
    "    \n",
    "    for i, lead_name in enumerate(fields['sig_name']):\n",
    "        axes[i].plot(time_axis, signal[:, i], linewidth=0.8)\n",
    "        axes[i].set_title(f'Lead {lead_name}')\n",
    "        axes[i].set_xlabel('Time (s)')\n",
    "        axes[i].set_ylabel('Amplitude (mV)')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'12-Lead ECG - Patient {sample_record[\"patient_id\"]}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load ECG: {str(e)}\")\n",
    "    print(\"   Make sure the records100 directory was downloaded and extracted correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-section"
   },
   "source": [
    "## üìã Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary"
   },
   "outputs": [],
   "source": [
    "print(\"üéâ PTB-XL Dataset Download Complete!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìÅ Dataset location: {PTB_XL_DIR}\")\n",
    "print(f\"üíæ Total size: ~{sum(f.stat().st_size for f in PTB_XL_DIR.rglob('*') if f.is_file()) / (1024**3):.2f} GB\")\n",
    "print()\n",
    "print(\"üìä Available files:\")\n",
    "print(f\"   ‚úÖ ptbxl_database.csv - {len(df):,} ECG records metadata\")\n",
    "print(f\"   ‚úÖ scp_statements.csv - {len(scp_df):,} diagnostic codes\")\n",
    "if (PTB_XL_DIR / \"records100\").exists():\n",
    "    count_100 = len(list((PTB_XL_DIR / \"records100\").rglob(\"*.dat\")))\n",
    "    print(f\"   ‚úÖ records100/ - {count_100:,} ECG files @ 100Hz\")\n",
    "if (PTB_XL_DIR / \"records500\").exists():\n",
    "    count_500 = len(list((PTB_XL_DIR / \"records500\").rglob(\"*.dat\")))\n",
    "    print(f\"   ‚úÖ records500/ - {count_500:,} ECG files @ 500Hz\")\n",
    "print()\n",
    "print(\"üöÄ Next Steps:\")\n",
    "print(\"1. Use this dataset in your ECG analysis pipeline\")\n",
    "print(\"2. Load ECG records with: wfdb.rdsamp(record_path)\")\n",
    "print(\"3. Access metadata with: pd.read_csv('ptbxl_database.csv')\")\n",
    "print(\"4. Implement signal processing and feature extraction\")\n",
    "print(\"5. Train ML models for ECG classification\")\n",
    "print()\n",
    "print(\"üìñ Useful resources:\")\n",
    "print(\"- PTB-XL Paper: https://www.nature.com/articles/s41597-020-0495-6\")\n",
    "print(\"- WFDB Documentation: https://wfdb.readthedocs.io/\")\n",
    "print(\"- PhysioNet: https://physionet.org/content/ptb-xl/\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PTB_XL_Dataset_Download.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
